{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Импорт библиотеки NumPy для работы с массивами и математическими функциями.\n",
    "import pandas as pd  # Импорт библиотеки Pandas для работы с данными в форме таблицы (DataFrame).\n",
    "from scipy.stats import f  # Импорт функции f из библиотеки SciPy для работы с распределением F.\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis  # Импорт класса LinearDiscriminantAnalysis из библиотеки scikit-learn для выполнения анализа дискриминантной функции.\n",
    "from scipy.spatial.distance import mahalanobis  # Импорт функции mahalanobis из библиотеки SciPy для вычисления расстояния Махаланобиса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные\n",
      "                    Регион        X1        X2        X3        X4        X5  \\\n",
      "0  Республика Башкортостан -0.358860  1.046662 -0.024135 -0.925109  1.108921   \n",
      "1      Вологодская область  0.732542  0.152726  1.493990  0.505787 -0.675489   \n",
      "2          Приморский край  1.213320  0.431885  0.657885 -0.079579 -0.394043   \n",
      "3      Ульяновская область -0.404481  0.220163 -0.531442 -0.014539 -0.572209   \n",
      "4       Смоленская область -0.014946  0.934528  0.457704  0.115543  1.480501   \n",
      "\n",
      "         X6        X7        X8        X9  \n",
      "0 -0.419513  0.043384 -0.222082  0.089137  \n",
      "1 -0.282279  0.282664 -0.269168 -0.647999  \n",
      "2 -0.191350 -0.072765  0.280705  0.014490  \n",
      "3 -0.460731 -0.228032 -0.575047  0.574341  \n",
      "4 -0.356004 -0.121853 -0.337658  0.210438  \n"
     ]
    }
   ],
   "source": [
    "FEATURES = [\"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\"]\n",
    "# Определение списка FEATURES, содержащего названия признаков, которые будут использоваться в анализе.\n",
    "\n",
    "TRAIN_SAMPLES = {\n",
    "    1: [3, 5, 7, 9, 13,14,16,17,23,24,26],\n",
    "    2: [32, 82],\n",
    "    3: [0, 4,20,25,28,34],\n",
    "    4: [10, 15, 19, 30, 43],\n",
    "    5: [1, 2,6,8,11,12]\n",
    "}\n",
    "# Определение словаря TRAIN_SAMPLES, где ключи - номера классов, а значения - индексы обучающих примеров для каждого класса.\n",
    "\n",
    "data = pd.read_excel(r'lab2_data.xlsx', usecols=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "# Загрузка данных из Excel-файла в объект DataFrame библиотеки Pandas, используя только указанные столбцы.\n",
    "\n",
    "data = data.loc[range(0, 85)]\n",
    "# Выборка первых 85 строк из данных, чтобы оставить только нужное количество образцов.\n",
    "\n",
    "print(\"Данные\")\n",
    "print(data.head())\n",
    "# Вывод первых нескольких строк данных для визуального ознакомления с ними.\n",
    "\n",
    "data_to_excel = data[FEATURES]\n",
    "# Выборка только тех столбцов данных, которые соответствуют признакам из списка FEATURES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка\n",
      "          X1        X2        X3        X4        X5        X6        X7  \\\n",
      "3  -0.404481  0.220163 -0.531442 -0.014539 -0.572209 -0.460731 -0.228032   \n",
      "5  -0.169356  0.071174 -0.518682  0.115543 -0.757220 -0.249657 -0.685495   \n",
      "7  -0.004418 -0.052723 -0.157175  0.570828 -0.301720 -0.525390  0.257490   \n",
      "9   0.237726  0.279759  0.376950 -0.144620 -0.058421 -0.388520  0.058677   \n",
      "13 -0.229015  0.302499 -0.458052  0.050502 -0.157032 -0.326353 -0.597239   \n",
      "14  0.097353 -0.503612 -0.666108 -0.274702 -0.707612 -0.359749 -0.375588   \n",
      "16 -0.204449 -0.350702 -0.881749 -0.144620 -0.454377 -0.492329 -0.288642   \n",
      "17  0.279838  0.152726 -0.303873 -0.339742 -0.391579 -0.404677  0.468514   \n",
      "23 -0.597494  0.057059 -0.607321  0.440747 -0.853039 -0.339016 -0.627050   \n",
      "24 -0.246561 -0.238568 -0.251461  0.180584  0.636843 -0.276508 -0.289557   \n",
      "26  0.111390  0.006873  0.364296  0.115543  0.566475 -0.430189 -0.290844   \n",
      "32 -1.643275  0.306420  1.614578 -0.404783  2.632094  4.957725  1.730076   \n",
      "82 -2.092469  2.085667  1.570590  0.765950 -0.434851  4.802291  2.326612   \n",
      "0  -0.358860  1.046662 -0.024135 -0.925109  1.108921 -0.419513  0.043384   \n",
      "4  -0.014946  0.934528  0.457704  0.115543  1.480501 -0.356004 -0.121853   \n",
      "20  0.023657  1.252111 -0.255348 -0.404783  0.472530  0.041704  0.686561   \n",
      "25 -0.007927  0.378562 -0.477267  0.115543  1.330328 -0.373201 -0.601984   \n",
      "28  0.858878  1.586945 -0.376519 -0.795027  1.507841 -0.394927 -0.104655   \n",
      "34  0.392137  0.522063 -0.600589 -1.380394  1.710050 -0.326985  1.318882   \n",
      "10 -0.351841 -0.880790 -1.023271 -1.055190  0.044369 -0.490078 -1.005689   \n",
      "15 -1.246720 -0.590653 -1.007924  0.050502  0.352542 -0.427326 -1.037718   \n",
      "19 -1.229174 -1.957435 -1.953633  0.505787 -0.200988 -0.543855 -1.402452   \n",
      "30  0.090334 -1.791194 -1.704387 -0.860068 -0.905773 -0.322221 -0.982052   \n",
      "43 -1.752064 -2.786287 -1.836503 -0.469824 -1.376447 -0.583393 -1.656322   \n",
      "1   0.732542  0.152726  1.493990  0.505787 -0.675489 -0.282279  0.282664   \n",
      "2   1.213320  0.431885  0.657885 -0.079579 -0.394043 -0.191350 -0.072765   \n",
      "6   0.964157 -0.098988  0.807300 -0.274702  0.383483 -0.316243  0.174423   \n",
      "8   0.472851  1.468538  0.346791  0.245624 -0.208946 -0.280892 -0.035065   \n",
      "11  1.290525 -0.309142  0.870309 -0.209661 -0.357398 -0.321622  0.808907   \n",
      "12  0.567603  0.685167  2.210513  0.375706  0.000741  0.298226  2.110889   \n",
      "\n",
      "          X8        X9  Class  \n",
      "3  -0.575047  0.574341      1  \n",
      "5  -0.219513  0.788950      1  \n",
      "7  -0.009948 -0.032164      1  \n",
      "9  -0.463079  0.173115      1  \n",
      "13 -0.391777  1.246161      1  \n",
      "14 -0.576026  0.565010      1  \n",
      "16 -0.524414 -0.004171      1  \n",
      "17 -0.413057  0.051814      1  \n",
      "23 -0.060642  1.106199      1  \n",
      "24 -0.816167  0.826273      1  \n",
      "26 -0.799106  0.201107      1  \n",
      "32  3.068472 -2.178257      2  \n",
      "82  3.892426 -1.991640      2  \n",
      "0  -0.222082  0.089137      3  \n",
      "4  -0.337658  0.210438      3  \n",
      "20 -0.501727 -0.564022      3  \n",
      "25 -0.069020 -0.666661      3  \n",
      "28 -0.601587  0.098468      3  \n",
      "34 -0.764739 -0.452052      3  \n",
      "10 -0.082656  0.481032      4  \n",
      "15 -0.074095  0.742296      4  \n",
      "19 -0.631306 -0.545360      4  \n",
      "30 -0.964948 -0.078818      4  \n",
      "43 -0.366460 -0.629338      4  \n",
      "1  -0.269168 -0.647999      5  \n",
      "2   0.280705  0.014490      5  \n",
      "6  -0.470417 -0.582684      5  \n",
      "8  -0.423208 -0.433390      5  \n",
      "11 -0.587277 -0.106811      5  \n",
      "12  0.160665 -0.508037      5  \n"
     ]
    }
   ],
   "source": [
    "def get_train_data(data, features, train_samples=None):\n",
    "    # Определение функции get_train_data, которая принимает три параметра: data (таблица с данными),\n",
    "    # features (список признаков) и train_samples (словарь с обучающими выборками для каждого класса).\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    # Создание нового пустого DataFrame под название train_data для хранения обучающих данных.\n",
    "\n",
    "    for cls, samples in train_samples.items():\n",
    "        # Итерация по элементам словаря train_samples, где cls - номер класса, samples - список индексов строк.\n",
    "\n",
    "        train_samps = data[features].loc[samples]\n",
    "        # Выборка строк из исходных данных (data) по указанным признакам (features) и номерам строк (samples).\n",
    "\n",
    "        train_samps[\"Class\"] = cls\n",
    "        # Добавление новой колонки \"Class\" с номером класса к выбранным обучающим данным.\n",
    "\n",
    "        train_data = pd.concat([train_data, train_samps])\n",
    "        # Объединение текущих обучающих данных с предыдущими в DataFrame train_data.\n",
    "\n",
    "    train_data = train_data.astype({\"Class\": 'int32'})\n",
    "    # Приведение типа данных в колонке \"Class\" к целочисленному (int32).\n",
    "\n",
    "    return train_data\n",
    "    # Возвращение итоговой обучающей выборки.\n",
    "\n",
    "train_data = get_train_data(data, FEATURES, TRAIN_SAMPLES)\n",
    "# Вызов функции get_train_data с передачей исходных данных, признаков и обучающих выборок.\n",
    "\n",
    "print(\"Обучающая выборка\")\n",
    "print(train_data)\n",
    "# Вывод на экран обучающей выборки.\n",
    "\n",
    "data_to_excel[\"Train sample\"] = train_data.Class\n",
    "# Добавление новой колонки \"Train sample\" с номерами классов в DataFrame data_to_excel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ковариационная матрица\n",
      "          X1        X2        X3        X4        X5        X6        X7  \\\n",
      "X1  0.181661  0.004324  0.008779 -0.108256  0.067262  0.001045  0.046240   \n",
      "X2  0.004324  0.337157  0.069779  0.051813 -0.032060  0.013827  0.052053   \n",
      "X3  0.008779  0.069779  0.218107  0.034740  0.089734  0.025628  0.115954   \n",
      "X4 -0.108256  0.051813  0.034740  0.218515 -0.069425  0.001306 -0.049241   \n",
      "X5  0.067262 -0.032060  0.089734 -0.069425  0.433285  0.003242  0.007033   \n",
      "X6  0.001045  0.013827  0.025628  0.001306  0.003242  0.022690  0.039366   \n",
      "X7  0.046240  0.052053  0.115954 -0.049241  0.007033  0.039366  0.307051   \n",
      "X8 -0.048223  0.070117  0.036325  0.062271 -0.069991  0.003450 -0.000296   \n",
      "X9  0.006715  0.112670  0.024192 -0.010606  0.033524  0.007528 -0.047733   \n",
      "\n",
      "          X8        X9  \n",
      "X1 -0.048223  0.006715  \n",
      "X2  0.070117  0.112670  \n",
      "X3  0.036325  0.024192  \n",
      "X4  0.062271 -0.010606  \n",
      "X5 -0.069991  0.033524  \n",
      "X6  0.003450  0.007528  \n",
      "X7 -0.000296 -0.047733  \n",
      "X8  0.103085  0.033522  \n",
      "X9  0.033522  0.186953  \n"
     ]
    }
   ],
   "source": [
    "def scatter_matrix(samples):\n",
    "    # Функция для вычисления матрицы рассеивания.\n",
    "    if isinstance(samples, pd.Series):\n",
    "        # Проверка, является ли samples объектом pd.Series (одномерным массивом).\n",
    "        samples = samples.to_frame()\n",
    "        # Преобразование pd.Series в pd.DataFrame, если необходимо.\n",
    "\n",
    "    d = samples - samples.mean()\n",
    "    # Вычисление отклонений значений признаков от их средних значений.\n",
    "\n",
    "    res = np.zeros((d.shape[1], d.shape[1]))\n",
    "    # Создание матрицы нулей размерности (число признаков) x (число признаков).\n",
    "\n",
    "    for _, row in d.iterrows():\n",
    "        # Итерация по строкам DataFrame d.\n",
    "        col = row.to_frame()\n",
    "        # Преобразование строки в pd.DataFrame.\n",
    "        res += col @ col.T\n",
    "        # Накапливание в res произведения строки на транспонированную версию этой строки.\n",
    "    return res\n",
    "    # Возвращение рассеивающей матрицы.\n",
    "\n",
    "def classes_scatter_matrix(samples, labels):\n",
    "    # Функция для вычисления классовой матрицы рассеивания.\n",
    "\n",
    "    A = np.zeros((samples.shape[1], samples.shape[1]))\n",
    "    # Создание матрицы нулей размерности (число признаков) x (число признаков).\n",
    "\n",
    "    for cls in labels.unique():\n",
    "        # Итерация по уникальным классам в labels.\n",
    "\n",
    "        A += scatter_matrix(samples[labels == cls])\n",
    "        # Накапливание в A матриц рассеивания для каждого класса.\n",
    "\n",
    "    return A\n",
    "    # Возвращение классовой матрицы рассеивания.\n",
    "\n",
    "cov = pd.DataFrame(\n",
    "    classes_scatter_matrix(train_data[FEATURES], train_data.Class) / (train_data.shape[0] - train_data.Class.unique().size),\n",
    "    index=FEATURES,\n",
    "    columns=FEATURES\n",
    ")\n",
    "# Вычисление ковариационной матрицы как отношение классовой матрицы рассеивания к числу степеней свободы.\n",
    "\n",
    "print(\"Ковариационная матрица\")\n",
    "print(cov)\n",
    "# Вывод ковариационной матрицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние значения\n",
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "1 -0.102679 -0.005032 -0.330420  0.050502 -0.277263 -0.386647 -0.236161   \n",
      "2 -1.867872  1.196044  1.592584  0.180584  1.098622  4.880008  2.028344   \n",
      "3  0.148823  0.953478 -0.212692 -0.545705  1.268362 -0.304821  0.203389   \n",
      "4 -0.897893 -1.601272 -1.505144 -0.365759 -0.417260 -0.473374 -1.216846   \n",
      "5  0.873500  0.388364  1.064465  0.093863 -0.208609 -0.182360  0.544842   \n",
      "\n",
      "         X8        X9  \n",
      "1 -0.440798  0.499694  \n",
      "2  3.480449 -2.084949  \n",
      "3 -0.416135 -0.214115  \n",
      "4 -0.423893 -0.006038  \n",
      "5 -0.218117 -0.377405  \n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis().fit(train_data[FEATURES], train_data.Class)\n",
    "# Создание и обучение модели линейного дискриминантного анализа (LDA) на обучающей выборке. \n",
    "# Результаты обучения (модель) присваиваются переменной lda.\n",
    "\n",
    "means = pd.DataFrame(lda.means_, index=lda.classes_, columns=FEATURES)\n",
    "# Извлечение средних значений признаков для каждого класса из обученной модели LDA.\n",
    "# Создание DataFrame means, где строки - классы, столбцы - признаки, и значения - средние значения.\n",
    "\n",
    "print(\"Средние значения\")  # Вывод заголовка для вывода средних значений.\n",
    "print(means)\n",
    "# Вывод на экран средних значений, представленных в виде DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние Махаланобиса (обучающая выборка)\n",
      "             1            2            3            4            5\n",
      "1          0.0  2109.473511    27.006252    19.438055    26.146941\n",
      "2  2109.473511          0.0  1915.552604  2003.434185  1974.660445\n",
      "3    27.006252  1915.552604          0.0    42.400077    35.303561\n",
      "4    19.438055  2003.434185    42.400077          0.0    64.286199\n",
      "5    26.146941  1974.660445    35.303561    64.286199          0.0\n"
     ]
    }
   ],
   "source": [
    "def find_mahl_sqr_dist(centers, samples, covr):\n",
    "    # Функция для вычисления квадрата махаланобисовского расстояния между центральными точками (centers) и образцами (samples).\n",
    "    # Принимает центральные точки (centers), образцы (samples) и матрицу ковариации (covr).\n",
    "\n",
    "    res = pd.DataFrame(index=samples.index, columns=centers.index)\n",
    "    # Создание нового DataFrame с номерами образцов в индексах и номерами центральных точек в столбцах.\n",
    "\n",
    "    for i in centers.index:\n",
    "        # Внешний цикл: итерация по номерам центральных точек.\n",
    "\n",
    "        for j in samples.index:\n",
    "            # Внутренний цикл: итерация по номерам образцов.\n",
    "\n",
    "            res[i][j] = mahalanobis(centers.loc[i], samples.loc[j], np.linalg.inv(covr)) ** 2\n",
    "            # Вычисление квадрата махаланобисовского расстояния между центральной точкой и образцом.\n",
    "            # mahalanobis - функция для вычисления расстояния Махаланобиса.\n",
    "            # np.linalg.inv(covr) - обратная матрица к матрице ковариации.\n",
    "\n",
    "    return res\n",
    "    # Возвращение DataFrame с квадратами махаланобисовских расстояний.\n",
    "\n",
    "cen_dis = find_mahl_sqr_dist(means, means, cov)\n",
    "# Вызов функции средних значений и матрицы ковариации для вычисления расстояний Махаланобиса.\n",
    "\n",
    "print(\"Расстояние Махаланобиса (обучающая выборка)\")\n",
    "print(cen_dis)\n",
    "# Вывод на экран расстояний Махаланобиса для обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции Фишера\n",
      "               1           2          3          4          5\n",
      "Const  -9.463106 -883.362229 -11.246590 -15.047315 -11.237278\n",
      "X1     -0.006032   -3.036954  -1.731631  -5.457422   7.302860\n",
      "X2     -2.231984   10.342525   5.214524  -5.380512  -0.086301\n",
      "X3      0.884354  -17.422424  -1.805371  -3.338163   8.773333\n",
      "X4      4.383918  -27.349974  -1.689419  -0.751414   3.395072\n",
      "X5     -2.402583   16.128704   3.459737  -0.912346  -3.670948\n",
      "X6    -27.037372  304.897414 -17.998959 -19.615652 -17.718619\n",
      "X7      4.869425  -40.220391   2.271270   2.414541   0.196130\n",
      "X8     -8.048628   67.285779  -1.667115  -2.095782  -4.259176\n",
      "X9      8.760000  -53.674466  -2.703127   6.143015  -0.584564\n",
      "Pi:  [0.36666667 0.06666667 0.2        0.16666667 0.2       ]\n"
     ]
    }
   ],
   "source": [
    "def get_def_coef(lda, features):\n",
    "    # Функция для получения дискриминантных коэффициентов.\n",
    "    # Принимает обученную модель LDA (lda) и список признаков (features).\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        np.vstack([lda.intercept_, lda.coef_.T]),\n",
    "        # Создание DataFrame из массива, содержащего результаты дискриминантного анализа:\n",
    "        # np.vstack объединяет массивы, lda.intercept_ - свободный член, lda.coef_.T - транспонированные коэффициенты при признаках.\n",
    "        # Интерпретация: строки - \"Const\" и признаки, столбцы - номера классов из модели LDA.\n",
    "\n",
    "        index=[\"Const\"] + features,\n",
    "        # Установка индекса DataFrame: первая строка - \"Const\", затем идут названия признаков.\n",
    "\n",
    "        columns=lda.classes_\n",
    "        # Установка столбцов DataFrame: номера классов из обученной модели LDA.\n",
    "    )\n",
    "\n",
    "df_coef = get_def_coef(lda, FEATURES)\n",
    "# Получение дискриминантных коэффициентов для обученной модели LDA и признаков из списка FEATURES.\n",
    "\n",
    "print(\"Функции Фишера\")\n",
    "print(df_coef)\n",
    "# Вывод на экран дискриминантных коэффициентов (функций Фишера).\n",
    "\n",
    "print(\"Pi: \", lda.priors_)\n",
    "# Вывод на экран априорных вероятностей классов, полученных из обученной модели LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по классам\n",
      "    Class\n",
      "0       3\n",
      "1       5\n",
      "2       5\n",
      "3       1\n",
      "4       3\n",
      "..    ...\n",
      "80      1\n",
      "81      3\n",
      "82      2\n",
      "83      2\n",
      "84      4\n",
      "\n",
      "[85 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def LDA_predict(lda, x):\n",
    "    # Функция для предсказания классов объектов с использованием обученной модели LDA.\n",
    "    # Принимает модель LDA (lda) и значения признаков объектов (x).\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        lda.predict(x),\n",
    "        # Применение метода predict модели LDA к значениям признаков объектов.\n",
    "        # Полученные предсказанные классы оборачиваются в DataFrame.\n",
    "\n",
    "        columns=[\"Class\"],\n",
    "        # Установка названия столбца в DataFrame: \"Class\".\n",
    "\n",
    "        index=x.index\n",
    "        # Установка индекса DataFrame: индексы объектов из исходной таблицы x.\n",
    "    )\n",
    "\n",
    "lda_predict = LDA_predict(lda, data[FEATURES])\n",
    "# Применение функции предсказания для всех объектов в исходной таблице признаков data.\n",
    "\n",
    "print(\"Распределение по классам\")\n",
    "print(lda_predict)\n",
    "# Вывод на экран предсказанных классов для каждого объекта.\n",
    "\n",
    "data_to_excel[\"Result Lda\"] = lda_predict\n",
    "# Добавление предсказанных классов в исходную таблицу data_to_excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние Махланобиса\n",
      "              1            2            3            4            5\n",
      "0     33.424341  1975.623082     7.270964    42.234347    49.451984\n",
      "1     41.187882  2070.540041    61.047235    84.943521     5.707424\n",
      "2     36.435201  1890.943842     43.56814    67.104718     8.674358\n",
      "3      2.612685  2183.499996     31.61648    21.820347    38.369075\n",
      "4     17.384371   2009.90347     7.213183    43.144658    24.679108\n",
      "..          ...          ...          ...          ...          ...\n",
      "80   170.320268  2417.409352   267.979411   176.675981   235.555432\n",
      "81   229.722763   1347.82224   200.855363   244.944911   239.323815\n",
      "82  2020.956288      9.00024  1837.818346  1926.668605  1886.081092\n",
      "83  1384.968853   199.330189  1230.644935  1263.019131   1269.31602\n",
      "84   156.251404  1781.006798   223.311443   148.278774   238.353581\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "samp_dist = find_mahl_sqr_dist(means, data[FEATURES], cov)\n",
    "# Вычисление квадрата махаланобисовского расстояния для каждого образца в исходных данных.\n",
    "# Используются средние значения (means) и матрица ковариации (cov), вычисленные на основе обучающей выборки.\n",
    "\n",
    "print(\"Расстояние Махланобиса\")\n",
    "print(samp_dist)\n",
    "# Вывод на экран квадратов махаланобисовских расстояний для каждого образца в исходных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities\n",
      "                1              2              3              4              5\n",
      "0    3.838011e-06   0.000000e+00   9.999961e-01   2.131155e-08   6.926379e-10\n",
      "1    3.620412e-08   0.000000e+00   9.618621e-13   5.187033e-18   1.000000e+00\n",
      "2    1.718107e-06   0.000000e+00   2.647956e-08   1.709332e-13   9.999983e-01\n",
      "3    9.999690e-01   0.000000e+00   2.745687e-07   3.066712e-05   9.383044e-09\n",
      "4    1.121062e-02   0.000000e+00   9.886300e-01   1.298470e-08   1.593516e-04\n",
      "..            ...            ...            ...            ...            ...\n",
      "80   9.814090e-01   0.000000e+00   3.328091e-22   1.859097e-02   3.655719e-15\n",
      "81   9.880175e-07  2.898581e-250   9.999990e-01   2.222770e-10   4.432831e-09\n",
      "82   0.000000e+00   1.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00\n",
      "83  1.915129e-257   1.000000e+00  3.388204e-224  2.635245e-231  1.357219e-232\n",
      "84   3.924642e-02   0.000000e+00   5.870244e-17   9.607536e-01   3.179049e-20\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def LDA_predict_probab(lda, x):\n",
    "    # Функция для предсказания апостериорных вероятностей классификации объектов с использованием обученной модели LDA.\n",
    "    # Принимает модель LDA (lda) и значения признаков объектов (x).\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        lda.predict_proba(x),\n",
    "        # функция возвращает результат в виде объекта DataFrame \n",
    "        # Применение метода predict_proba модели LDA к значениям признаков объектов.\n",
    "        # Полученные апостериорные вероятности классификации оборачиваются в DataFrame.\n",
    "\n",
    "        columns=lda.classes_,\n",
    "        # Установка названий столбцов в DataFrame: номера классов из обученной модели LDA.\n",
    "\n",
    "        index=x.index\n",
    "        # Установка индекса DataFrame: индексы объектов из исходной таблицы x.\n",
    "    )\n",
    "\n",
    "lda_post_prob = LDA_predict_probab(lda, data[FEATURES])\n",
    "# Применение функции предсказания апостериорных вероятностей для всех объектов в исходной таблице признаков data.\n",
    "\n",
    "print(\"Probabilities\")\n",
    "print(lda_post_prob)\n",
    "# Вывод на экран апостериорных вероятностей классификации для каждого объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\810604693.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward stepwise\n",
      "Step:  0\n",
      "Empty DataFrame\n",
      "Columns: [Wilk's lmbd, Partial lmbd, F to enter, P value]\n",
      "Index: []\n",
      "\n",
      "Step:  1\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6          1.0      0.010968  563.567943  4.243256e-24\n",
      "\n",
      "Step:  2\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.182669      0.013022  454.749142  3.054442e-22\n",
      "X3     0.010968      0.216875   21.665769  1.125722e-07\n",
      "\n",
      "Step:  3\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.079690      0.012962  437.848549  2.440584e-21\n",
      "X3     0.003378      0.305751   13.056141  1.084419e-05\n",
      "X2     0.002379      0.434242    7.491472  5.120760e-04\n",
      "\n",
      "Step:  4\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.022380      0.022444  239.549371  8.557618e-18\n",
      "X3     0.001556      0.322827   11.536989  3.353272e-05\n",
      "X2     0.001354      0.371027    9.323724  1.452490e-04\n",
      "X9     0.001033      0.486279    5.810376  2.391247e-03\n",
      "\n",
      "Step:  5\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.011325      0.022310  230.069455  5.140736e-17\n",
      "X3     0.000866      0.291742   12.745383  2.035423e-05\n",
      "X2     0.000613      0.412291    7.483721  6.534583e-04\n",
      "X9     0.000517      0.489116    5.483652  3.487976e-03\n",
      "X5     0.000502      0.502994    5.187510  4.571889e-03\n",
      "\n",
      "Step:  6\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.003269      0.053623   88.244285  2.056677e-12\n",
      "X3     0.000384      0.455946    5.966215  2.500662e-03\n",
      "X2     0.000410      0.427340    6.700284  1.366255e-03\n",
      "X9     0.000348      0.503000    4.940350  6.189523e-03\n",
      "X5     0.000368      0.475646    5.512028  3.700549e-03\n",
      "X1     0.000253      0.693726    2.207452  1.048820e-01\n",
      "\n",
      "Step:  7\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.001000      0.133263   30.893829  4.468153e-08\n",
      "X3     0.000306      0.436128    6.141299  2.396458e-03\n",
      "X2     0.000300      0.443591    5.958064  2.784208e-03\n",
      "X9     0.000274      0.486334    5.016944  6.240881e-03\n",
      "X5     0.000287      0.464131    5.484185  4.147197e-03\n",
      "X1     0.000179      0.743836    1.635813  2.064330e-01\n",
      "X8     0.000175      0.760324    1.497337  2.426351e-01\n",
      "\n",
      "Step:  8\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.000846      0.129175   30.336462  8.849770e-08\n",
      "X3     0.000234      0.466269    5.151072  6.045444e-03\n",
      "X2     0.000216      0.506941    4.376778  1.202310e-02\n",
      "X9     0.000238      0.459157    5.300580  5.322389e-03\n",
      "X5     0.000235      0.464119    5.195796  5.818392e-03\n",
      "X1     0.000153      0.713515    1.806804  1.715194e-01\n",
      "X8     0.000135      0.808911    1.063036  4.033139e-01\n",
      "X7     0.000133      0.819927    0.988295  4.389208e-01\n",
      "\n",
      "Step:  9\n",
      "    Wilk's lmbd  Partial lmbd  F to enter       P value\n",
      "X6     0.000668      0.129421   28.588470  2.378626e-07\n",
      "X3     0.000137      0.633030    2.463741  8.451321e-02\n",
      "X2     0.000171      0.505038    4.165215  1.566225e-02\n",
      "X9     0.000206      0.419783    5.874274  3.705975e-03\n",
      "X5     0.000145      0.594321    2.901023  5.337870e-02\n",
      "X1     0.000123      0.701010    1.812685  1.729142e-01\n",
      "X8     0.000109      0.791578    1.119021  3.801244e-01\n",
      "X7     0.000110      0.787490    1.146896  3.683166e-01\n",
      "X4     0.000109      0.790827    1.124121  3.779379e-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def wilks_lambda(samples, labels):\n",
    "    # Функция для вычисления критерия Вилкса.\n",
    "    # Принимает samples - значения признаков в обучающей выборке и labels - номера классов.\n",
    "    if isinstance(samples, pd.Series):\n",
    "        samples = samples.to_frame()\n",
    "    # Проверка, если samples - это pd.Series (одномерный массив), преобразует в pd.DataFrame.\n",
    "    # Вычисление определителей матриц рассеивания.\n",
    "    dT = np.linalg.det(scatter_matrix(samples))\n",
    "    dE = np.linalg.det(classes_scatter_matrix(samples, labels))\n",
    "    return dE / dT\n",
    "    # Возвращение отношения определителей.\n",
    "def f_p_value(lmbd, n_obj, n_sign, n_cls):\n",
    "    # Функция для вычисления F-статистики и p-значения.\n",
    "    # Принимает lmbd - значение лямбды, n_obj - число объектов в обучающей выборке,\n",
    "    # n_sign - число признаков в модели, n_cls - число классов в обучающей выборке.\n",
    "    num = (1 - lmbd) * (n_obj - n_cls - n_sign)\n",
    "    den = lmbd * (n_cls - 1)\n",
    "    f_value = num / den\n",
    "    p = f.sf(f_value, n_cls - 1, n_obj - n_cls - n_sign)\n",
    "    return f_value, p\n",
    "    # Возвращение значения F-статистики и p-значения.\n",
    "def forward(samples, labels, f_in=1e-4):\n",
    "    # Функция для выполнения пошагового вперёд метода.\n",
    "    # Принимает samples - значения признаков в обучающей выборке, labels - номера классов, f_in - точность.\n",
    "    st_columns = [\"Wilk's lmbd\", \"Partial lmbd\", \"F to enter\", \"P value\"]\n",
    "    # Создание списка названий колонок для таблицы результатов.\n",
    "    n_cls = labels.unique().size\n",
    "    n_obj = samples.shape[0]\n",
    "    # Получение числа уникальных классов и числа объектов в обучающей выборке.\n",
    "    out = {0: pd.DataFrame(columns=st_columns, index=samples.columns, dtype=float)}\n",
    "    into = {0: pd.DataFrame(columns=st_columns, dtype=float)}\n",
    "    # Создание словарей для хранения результатов внутри и вне модели.\n",
    "    step = 0\n",
    "    # Инициализация переменной для отслеживания шага.\n",
    "    while True:\n",
    "        model_lmbd = wilks_lambda(samples[into[step].index], labels)\n",
    "        # Расчёт характеристик элементов вне модели.\n",
    "        for el in out[step].index:\n",
    "            lmbda = wilks_lambda(samples[into[step].index.tolist() + [el]], labels)\n",
    "            partial_lmbd = lmbda / model_lmbd\n",
    "            f_lmbd, p_value = f_p_value(partial_lmbd, n_obj, into[step].index.size, n_cls)\n",
    "            out[step].loc[el] = lmbda, partial_lmbd, f_lmbd, p_value\n",
    "        # Расчёт характеристик элементов в модели.\n",
    "        for el in into[step].index:\n",
    "            lmbda = wilks_lambda(samples[into[step].index.drop(el)], labels)\n",
    "            partial_lmbd = model_lmbd / lmbda\n",
    "            f_lmbd, p_value = f_p_value(partial_lmbd, n_obj, into[step].index.size - 1, n_cls)\n",
    "            into[step].loc[el] = lmbda, partial_lmbd, f_lmbd, p_value\n",
    "\n",
    "        if out[step].index.size == 0 or out[step][\"F to enter\"].max() < f_in:\n",
    "            break\n",
    "        # Добавление нового элемента.\n",
    "        el_to_enter = out[step][\"F to enter\"].idxmax()\n",
    "        into[step + 1] = into[step].append(out[step].loc[el_to_enter])\n",
    "        out[step + 1] = out[step].drop(index=el_to_enter)\n",
    "        step += 1\n",
    "    return into, out\n",
    "    # Возвращение результатов внутри и вне модели.\n",
    "into, out = forward(train_data[FEATURES], train_data.Class)\n",
    "print(\"Forward stepwise\")\n",
    "for i, tab in into.items():\n",
    "    print(\"Step: \", i)\n",
    "    print(tab, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции Фишера\n",
      "               1           2          3          4          5\n",
      "Const  -5.490569 -614.493150  -9.785350 -11.993173  -7.706877\n",
      "X6    -19.928106  243.915734 -14.335540 -16.091511 -17.025251\n",
      "X3      1.920231  -23.603277  -1.631986  -2.814443   8.324691\n",
      "X2     -1.626621    6.540954   5.119666  -5.519199   0.281486\n",
      "X9      4.904824  -22.819841  -3.717785   4.943243  -1.787148\n",
      "X5     -1.651412    7.585311   3.775958  -1.313661  -2.182089\n",
      "Pi:  [0.36666667 0.06666667 0.2        0.16666667 0.2       ]\n",
      "Распределение\n",
      "   Class\n",
      "0      3\n",
      "1      5\n",
      "2      5\n",
      "3      1\n",
      "4      3\n"
     ]
    }
   ],
   "source": [
    "forw_stepwise = into[len(into) - 5].index.tolist()\n",
    "# Выбираем признаки, которые были включены в модель на пятом предыдущем шаге (назад) метода пошагового вперёдного отбора.\n",
    "\n",
    "forw_stepwise_lda = LinearDiscriminantAnalysis().fit(train_data[forw_stepwise], train_data.Class)\n",
    "# Обучаем модель линейного дискриминантного анализа (LDA) на выбранных признаках.\n",
    "\n",
    "forw_stepwise_coef = get_def_coef(forw_stepwise_lda, forw_stepwise)\n",
    "# Получаем коэффициенты функции Фишера для выбранных признаков.\n",
    "\n",
    "print(\"Функции Фишера\")\n",
    "print(forw_stepwise_coef)\n",
    "# Выводим коэффициенты функции Фишера.\n",
    "\n",
    "print(\"Pi: \", forw_stepwise_lda.priors_)\n",
    "# Выводим априорные вероятности классов в модели LDA.\n",
    "\n",
    "forw_stepwise_pred = LDA_predict(forw_stepwise_lda, data[forw_stepwise])\n",
    "# Получаем прогнозы модели LDA для выбранных признаков.\n",
    "\n",
    "print(\"Распределение\")\n",
    "print(forw_stepwise_pred.head())\n",
    "# Выводим распределение классов для первых нескольких объектов.\n",
    "\n",
    "data_to_excel[\"Result forward\"] = forw_stepwise_pred\n",
    "# Записываем результаты прогнозирования в таблицу data_to_excel под именем \"Result forward\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
      "C:\\Users\\Максим\\AppData\\Local\\Temp\\ipykernel_32092\\2300776718.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward stepwise\n",
      "Step:  0\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X1     0.000123      0.701010     1.812685  1.729142e-01\n",
      "X2     0.000171      0.505038     4.165215  1.566225e-02\n",
      "X3     0.000137      0.633030     2.463741  8.451321e-02\n",
      "X4     0.000109      0.790827     1.124121  3.779379e-01\n",
      "X5     0.000145      0.594321     2.901023  5.337870e-02\n",
      "X6     0.000668      0.129421    28.588470  2.378626e-07\n",
      "X7     0.000110      0.787490     1.146896  3.683166e-01\n",
      "X8     0.000109      0.791578     1.119021  3.801244e-01\n",
      "X9     0.000206      0.419783     5.874274  3.705975e-03\n",
      "\n",
      "Step:  1\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X1     0.000170      0.641654     2.513125  7.790170e-02\n",
      "X2     0.000239      0.456797     5.351200  5.099635e-03\n",
      "X3     0.000175      0.624640     2.704144  6.338262e-02\n",
      "X4     0.000135      0.808143     1.068320  4.008982e-01\n",
      "X5     0.000180      0.605414     2.932935  4.972825e-02\n",
      "X6     0.002162      0.050499    84.610139  2.038767e-11\n",
      "X7     0.000148      0.737671     1.600278  2.173847e-01\n",
      "X9     0.000256      0.427024     6.038050  2.906862e-03\n",
      "\n",
      "Step:  2\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X1     0.000199      0.678959     2.246000  1.023196e-01\n",
      "X2     0.000289      0.466640     5.429159  4.348052e-03\n",
      "X3     0.000291      0.464512     5.475777  4.177217e-03\n",
      "X5     0.000287      0.471318     5.328132  4.745201e-03\n",
      "X6     0.002778      0.048624    92.938459  3.363014e-12\n",
      "X7     0.000175      0.770678     1.413402  2.676237e-01\n",
      "X9     0.000293      0.461388     5.545018  3.936922e-03\n",
      "\n",
      "Step:  3\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X1     0.000253      0.693726     2.207452  1.048820e-01\n",
      "X2     0.000410      0.427340     6.700284  1.366255e-03\n",
      "X3     0.000384      0.455946     5.966215  2.500662e-03\n",
      "X5     0.000368      0.475646     5.512028  3.700549e-03\n",
      "X6     0.003269      0.053623    88.244285  2.056677e-12\n",
      "X9     0.000348      0.503000     4.940350  6.189523e-03\n",
      "\n",
      "Step:  4\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X2     0.000613      0.412291     7.483721  6.534583e-04\n",
      "X3     0.000866      0.291742    12.745383  2.035423e-05\n",
      "X5     0.000502      0.502994     5.187510  4.571889e-03\n",
      "X6     0.011325      0.022310   230.069455  5.140736e-17\n",
      "X9     0.000517      0.489116     5.483652  3.487976e-03\n",
      "\n",
      "Step:  5\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X2     0.001354      0.371027     9.323724  1.452490e-04\n",
      "X3     0.001556      0.322827    11.536989  3.353272e-05\n",
      "X6     0.022380      0.022444   239.549371  8.557618e-18\n",
      "X9     0.001033      0.486279     5.810376  2.391247e-03\n",
      "\n",
      "Step:  6\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X2     0.002379      0.434242     7.491472  5.120760e-04\n",
      "X3     0.003378      0.305751    13.056141  1.084419e-05\n",
      "X6     0.079690      0.012962   437.848549  2.440584e-21\n",
      "\n",
      "Step:  7\n",
      "    Wilk's lmbd  Partial lmbd  F to remove       P value\n",
      "X3     0.010968      0.216875    21.665769  1.125722e-07\n",
      "X6     0.182669      0.013022   454.749142  3.054442e-22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def backward(samples, labels, f_r=10.00):\n",
    "    # Определение списка названий столбцов для выходных таблиц\n",
    "    st_columns = [\"Wilk's lmbd\", \"Partial lmbd\", \"F to remove\", \"P value\"]\n",
    "    # Получение количества уникальных классов в метках\n",
    "    n_cls = labels.unique().size\n",
    "    # Получение количества объектов в выборке\n",
    "    n_obj = samples.shape[0]\n",
    "    \n",
    "    # Инициализация словарей для хранения переменных внутри и вне модели\n",
    "    into = {0: pd.DataFrame(columns=st_columns, index=samples.columns, dtype=float)}\n",
    "    out = {0: pd.DataFrame(columns=st_columns, dtype=float)}\n",
    "    # Инициализация счетчика шагов\n",
    "    step = 0\n",
    "\n",
    "    # Запуск цикла, который выполняется до достижения условия выхода\n",
    "    while True:\n",
    "        # Расчет значения лямбда Уилкса для текущей модели\n",
    "        model_lmbd = wilks_lambda(samples[into[step].index], labels)\n",
    "        \n",
    "        # Расчет характеристик для элементов вне модели\n",
    "        for el in out[step].index:\n",
    "            lmbda = wilks_lambda(samples[into[step].index.tolist() + [el]], labels)\n",
    "            partial_lmbd = lmbda / model_lmbd\n",
    "            f_lmbd, p_value = f_p_value(partial_lmbd, n_obj, into[step].index.size, n_cls)\n",
    "            out[step].loc[el] = lmbda, partial_lmbd, f_lmbd, p_value\n",
    "        \n",
    "        # Расчет характеристик для элементов внутри модели\n",
    "        for el in into[step].index:\n",
    "            lmbda = wilks_lambda(samples[into[step].index.drop(el)], labels)\n",
    "            partial_lmbd = model_lmbd / lmbda\n",
    "            f_lmbd, p_value = f_p_value(partial_lmbd, n_obj, into[step].index.size - 1, n_cls)\n",
    "            into[step].loc[el] = lmbda, partial_lmbd, f_lmbd, p_value\n",
    "\n",
    "        # Проверка условия выхода\n",
    "        if into[step].index.size == 0 or into[step][\"F to remove\"].min() > f_r:\n",
    "            break\n",
    "        \n",
    "        # Удаление элемента с минимальным значением F\n",
    "        el_to_remove = into[step][\"F to remove\"].idxmin()\n",
    "        out[step + 1] = out[step].append(into[step].loc[el_to_remove])\n",
    "        into[step + 1] = into[step].drop(index=el_to_remove)\n",
    "\n",
    "        # Инкремент счетчика шагов\n",
    "        step += 1\n",
    "    \n",
    "    # Возвращение окончательных словарей, содержащих переменные внутри и вне модели\n",
    "    return into, out\n",
    "\n",
    "\n",
    "# Вызов функции backward с указанными аргументами\n",
    "into, out = backward(train_data[FEATURES], train_data.Class)\n",
    "\n",
    "# Вывод результатов для каждого шага\n",
    "print(\"Backward stepwise\")\n",
    "for i, tab in into.items():\n",
    "    print(\"Step: \", i)\n",
    "    print(tab, end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X2', 'X3', 'X5', 'X6', 'X9']\n",
      "Функции Фишера\n",
      "               1           2          3          4          5\n",
      "Const  -5.490569 -614.493150  -9.785350 -11.993173  -7.706877\n",
      "X2     -1.626621    6.540954   5.119666  -5.519199   0.281486\n",
      "X3      1.920231  -23.603277  -1.631986  -2.814443   8.324691\n",
      "X5     -1.651412    7.585311   3.775958  -1.313661  -2.182089\n",
      "X6    -19.928106  243.915734 -14.335540 -16.091511 -17.025251\n",
      "X9      4.904824  -22.819841  -3.717785   4.943243  -1.787148\n",
      "Pi:  [0.36666667 0.06666667 0.2        0.16666667 0.2       ]\n",
      "Распределение\n",
      "   Class\n",
      "0      3\n",
      "1      5\n",
      "2      5\n",
      "3      1\n",
      "4      3\n"
     ]
    }
   ],
   "source": [
    "# Выбор индексов переменных, оставшихся после шага обратного пошагового отбора\n",
    "back_stepwise = into[len(into) - 4].index.tolist()\n",
    "print(back_stepwise)\n",
    "\n",
    "# Обучение модели LDA на выбранных переменных\n",
    "back_stepwise_lda = LinearDiscriminantAnalysis().fit(train_data[back_stepwise], train_data.Class)\n",
    "\n",
    "# Получение коэффициентов дискриминантных функций\n",
    "back_stepwise_coef = get_def_coef(back_stepwise_lda, back_stepwise)\n",
    "print(\"Функции Фишера\")\n",
    "print(back_stepwise_coef)\n",
    "\n",
    "# Вывод априорных вероятностей классов\n",
    "print(\"Pi: \", back_stepwise_lda.priors_)\n",
    "\n",
    "# Предсказание классов на основе обученной модели LDA и выбранных переменных\n",
    "back_stepwise_pred = LDA_predict(back_stepwise_lda, data[back_stepwise])\n",
    "\n",
    "# Вывод распределения классов для первых нескольких записей\n",
    "print(\"Распределение\")\n",
    "print(back_stepwise_pred.head())\n",
    "\n",
    "# Добавление предсказанных результатов в DataFrame \"data_to_excel\"\n",
    "data_to_excel[\"Result backward\"] = back_stepwise_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_excel.to_excel(r'Train sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
